{
  "script": {
    "name": "gen-ai-foundations-draft",
    "wrapup_video_id": null,
    "login_required": false,
    "properties": {
      "is_course": true,
      "is_migrated": true,
      "version_year": "unversioned"
    },
    "new_name": null,
    "family_name": "gen-ai-foundations-draft",
    "serialized_at": "2024-02-09 23:35:42 UTC",
    "published_state": "in_development",
    "instruction_type": "teacher_led",
    "instructor_audience": "teacher",
    "participant_audience": "student",
    "seeding_key": {
      "script.name": "gen-ai-foundations-draft"
    }
  },
  "lesson_groups": [
    {
      "key": "",
      "user_facing": false,
      "position": 1,
      "properties": {
      },
      "seeding_key": {
        "lesson_group.key": "",
        "script.name": "gen-ai-foundations-draft"
      }
    }
  ],
  "lessons": [
    {
      "key": "lesson-1",
      "name": "Lesson 1",
      "absolute_position": 1,
      "lockable": false,
      "has_lesson_plan": true,
      "relative_position": 1,
      "properties": {
      },
      "seeding_key": {
        "lesson.key": "lesson-1",
        "lesson_group.key": "",
        "script.name": "gen-ai-foundations-draft"
      }
    },
    {
      "key": "lesson-2",
      "name": "Lesson 2",
      "absolute_position": 2,
      "lockable": false,
      "has_lesson_plan": true,
      "relative_position": 2,
      "properties": {
      },
      "seeding_key": {
        "lesson.key": "lesson-2",
        "lesson_group.key": "",
        "script.name": "gen-ai-foundations-draft"
      }
    },
    {
      "key": "lesson-3",
      "name": "Lesson 3",
      "absolute_position": 3,
      "lockable": false,
      "has_lesson_plan": true,
      "relative_position": 3,
      "properties": {
      },
      "seeding_key": {
        "lesson.key": "lesson-3",
        "lesson_group.key": "",
        "script.name": "gen-ai-foundations-draft"
      }
    },
    {
      "key": "lesson-4",
      "name": "Lesson 4",
      "absolute_position": 4,
      "lockable": false,
      "has_lesson_plan": true,
      "relative_position": 4,
      "properties": {
      },
      "seeding_key": {
        "lesson.key": "lesson-4",
        "lesson_group.key": "",
        "script.name": "gen-ai-foundations-draft"
      }
    },
    {
      "key": "lesson-5",
      "name": "Lesson 5",
      "absolute_position": 5,
      "lockable": false,
      "has_lesson_plan": true,
      "relative_position": 5,
      "properties": {
      },
      "seeding_key": {
        "lesson.key": "lesson-5",
        "lesson_group.key": "",
        "script.name": "gen-ai-foundations-draft"
      }
    }
  ],
  "lesson_activities": [
    {
      "key": "5a041a6e-6665-460e-abd1-33cf8ebaa862",
      "position": 1,
      "properties": {
      },
      "seeding_key": {
        "lesson_activity.key": "5a041a6e-6665-460e-abd1-33cf8ebaa862",
        "lesson.key": "lesson-2",
        "lesson_group.key": "",
        "script.name": "gen-ai-foundations-draft"
      }
    }
  ],
  "activity_sections": [
    {
      "key": "cc099d73-e862-4dba-a446-0daa0ea9e364",
      "position": 1,
      "properties": {
        "description": "| Slide                                                                                                        | Lesson Guide                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n| ------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |\n| ![](https://dancodedotorg.github.io/testing-slides/1FFfEhrNW-oNuq5dAk-yYxT6cxuPYxz19QdXr97T1PiI/slide0.png)  | <p><br></p>|\n| ![](https://dancodedotorg.github.io/testing-slides/1FFfEhrNW-oNuq5dAk-yYxT6cxuPYxz19QdXr97T1PiI/slide1.png)  | <p><br></p>|\n| ![](https://dancodedotorg.github.io/testing-slides/1FFfEhrNW-oNuq5dAk-yYxT6cxuPYxz19QdXr97T1PiI/slide2.png)  | <p><br></p>|\n| ![](https://dancodedotorg.github.io/testing-slides/1FFfEhrNW-oNuq5dAk-yYxT6cxuPYxz19QdXr97T1PiI/slide3.png)  | <p><i class=\"fa fa-microphone\" aria-hidden=\"true\"></i> <strong>Say:</strong> In this comic, Calvin and Hobbes are playing Scrabble - a game where you score points based on the words you can create with random letters. On the next screen, you will see a list of “words”. Decide which ones are truly words like you can play in Scrabble and which are not.<br><br><details style=\"background-color: #FFA400; padding: 10px; margin-bottom: 10px; border: 1px solid transparent; border-radius: 5px; color: white\"><summary style=\"font-size: 1.2em; font-weight: bold;\"><i class=\"fa fa-lightbulb-o \"></i> Teaching Tip: Classroom Prep</summary><br>Before beginning this warmup, consider how you will manage the discussion on the next slide where students are sorting terms into “words” or “not words”. Consider having two sheets of poster paper that you can write on as the class sorts, or consider making a table on a whiteboard and writing the results there. You could also consider presenting these slides in “edit” mode so you can move the text boxes around on the screen, but make sure you are able to reset the choices between class periods if you teach this lesson to multiple classes in the same day.</details></p>|\n| ![](https://dancodedotorg.github.io/testing-slides/1FFfEhrNW-oNuq5dAk-yYxT6cxuPYxz19QdXr97T1PiI/slide4.png)  | <p><i class=\"fa fa-comments\" aria-hidden=\"true\"></i> <strong>Discuss:</strong> Have students discuss in groups before sharing out as a full class. Instead of going line-by-line through these words, ask students which decisions they are “most confident” about and sharing their classification for those words first. Using this strategy, students will likely sort “1) banana” and “6) shirt” as words, and “2) aka7sj23ksw” and “7) @&#x26;!*@^#” as not words. The remaining words are deliberately chosen to motivate certain discussions and create moments of cognitive dissonance and curiosity, hopefully allowing students to lead the discussion by asking questions or respectfully challenging ideas. Let students know they will likely change their minds as the discussion continues and that’s okay, and allowing students to state their confidence level for their initial thoughts can make them more comfortable speaking up since it feels less “high-stakes”. Be prepared to address the following situations in this discussion:<br></p><ul><li>3) <a href=\"https://en.wikipedia.org/wiki/Cherimoya\">cherimoya</a> is a fruit common to South America, but may not be a common fruit your students have heard of. It’s possible many students may say “this isn’t a word”, but one or two students may speak up because they’re familiar with this fruit. Be sure to elevate those voices and highlight how our own knowledge is sometimes limited by lack of exposure to different words or phrases. Or, if no one raises this point, be sure to point this out to students explicitly such as showing them the Wikipedia page. In either case, make sure cherimoya is classified as a “word” before leaving the discussion</li><li>8) ullaakkut and 10) yá'át'ééh are both words in other languages - <a href=\"https://www.adventurecanada.com/canadian-high-arctic-and-greenland/ullaakkut-a-guide-to-inuktitut-for-beginners\">ullaakkut means hello in Inuktitut</a>, a language spoken by Inuit peoples in Canada and Greenland; and <a href=\"https://www.youtube.com/watch?v=_h0tbtlZx0A\">yá'át'ééh means “hello” in the Navajo / Diné language</a>. Similar to above, students may initially classify these as not words because they are unfamiliar with them, but it is important to surface the meaning and use of these words to students either with a quick google search or elevating the voice of a student in class who is already familiar with these words. As a result, make sure these terms don’t end up in the “Not Words” category by the end of the discussion.</li><li>4) wierd is a misspelling of either the word “weird” or the word “wired”. Students may initially say that this is “not a word”, but another student or yourself should challenge them by pointing out that if this is typed into a device with autocorrect, it will automatically correct it to one of these other words. Even in this slide deck, the word has a red squiggly underline representing that the computer recognizes it as something, even if it’s not a correctly spelled word. This may inspire the class to create a new category to represent this term - it’s not a correctly spelled word, but it’s also not a made-up word, so maybe there’s a new category for “misspelled words” or “important terms that aren’t words”. Let students guide how they want to handle this situation, even if they decide not to make a new category and it remains in “not word”.</li><li>At some point, students who are more familiar with the Scrabble game may try to invoke the “rules of Scrabble” which restrict words in other languages, proper nouns, or abbreviations. From this perspective, words (8) and (10) above would be restricted, as would 5) Reykjavik (the capital of Iceland) and 9) ATM (since it is an abbreviation for Automatic Teller Machine). If this comes up, use this as an opportunity to question the effect that arbitrary rules have on what we consider valid language, since these are all definitely words that are used in society even if not officially allowed in Scrabble. You could consider creating new categories to represent these phrases, such as “Still words but not allowed in Scrabble” or “Part of language, but not allowed in Scrabble”. Or, the class could decide these belong in the Words category, regardless of what Scrabble thinks, and that’s the end of the story.</li></ul><p><br><i class=\"fa fa-lightbulb-o\" aria-hidden=\"true\"></i> <strong>Discussion Goal:</strong> Ultimately, this is an exercise to surface that the way we identify words versus nonsense - much like Calvin and Hobbes in the comic panel - can be contextual to our lived experiences and influences what we consider important information versus random noise that can be ignored. It’s okay if the discussion ends without closure, so long as students have wrestled with how what they initially considered “words” may have been expanded as they were exposed to new contexts in the discussion. However, be very intentional that the discussion ends with very few items in the “Not Words” category, especially making sure ullaakkut and yá'át'ééh are not in this category and are instead classified as either a Word or a new category the class has created.<br></p>|\n| ![](https://dancodedotorg.github.io/testing-slides/1FFfEhrNW-oNuq5dAk-yYxT6cxuPYxz19QdXr97T1PiI/slide5.png)  | <p><i class=\"fa fa-microphone\" aria-hidden=\"true\"></i> <strong>Say:</strong> Just from this warm-up, we’ve already seen that it can be tricky trying to recognize “words” from non-words. For a large-language model, those words are the inputs it uses to start generating it’s response. Today, we’re going to explore how a computer is able to recognize words used in language. This is the first step in understanding how a large-language model words - by looking at the inputs it uses!<br></p>|\n| ![](https://dancodedotorg.github.io/testing-slides/1FFfEhrNW-oNuq5dAk-yYxT6cxuPYxz19QdXr97T1PiI/slide6.png)  | <p><br></p>|\n| ![](https://dancodedotorg.github.io/testing-slides/1FFfEhrNW-oNuq5dAk-yYxT6cxuPYxz19QdXr97T1PiI/slide7.png)  | <p><i class=\"fa fa-microphone\" aria-hidden=\"true\"></i> <strong>Say:</strong> When you use a large-language model, you start by giving it a prompt. In this example, we’re asking it for a recipe for making chili.<br></p>|\n| ![](https://dancodedotorg.github.io/testing-slides/1FFfEhrNW-oNuq5dAk-yYxT6cxuPYxz19QdXr97T1PiI/slide8.png)  | <p><i class=\"fa fa-microphone\" aria-hidden=\"true\"></i> <strong>Say:</strong> As a first step, the model breaks apart this input into individual pieces.<br><br><img src=\"https://curriculum.code.org/media/uploads/animation.png\" /> Click the animation<br><br><i class=\"fa fa-microphone\" aria-hidden=\"true\"></i> <strong>Say:</strong> Usually this is word by word<br></p>|\n| ![](https://dancodedotorg.github.io/testing-slides/1FFfEhrNW-oNuq5dAk-yYxT6cxuPYxz19QdXr97T1PiI/slide9.png)  | <p><i class=\"fa fa-microphone\" aria-hidden=\"true\"></i> <strong>Say:</strong> But sometimes it’s even smaller, like when there is a root word or for punctuation. Technically, these are called tokens - they’re the smallest unit of data that a large-language model can represent.<br><br><i class=\"fa fa-microphone\" aria-hidden=\"true\"></i> <strong>Say:</strong> So then how does a large-language model learn how to recognize these words and tokens? And what words can it use when generating a response? Well - that’s exactly what we’re going to learn about today!<br><br><details style=\"background-color: #FFA400; padding: 10px; margin-bottom: 10px; border: 1px solid transparent; border-radius: 5px; color: white\"><summary style=\"font-size: 1.2em; font-weight: bold;\"><i class=\"fa fa-lightbulb-o \"></i> Teaching Tip: Viewing Tokens</summary><br>If your school district allows access, OpenAI has a website that lets you preview how it interprets words and converts them into tokens: <a href=\"https://platform.openai.com/tokenizer\">https://platform.openai.com/tokenizer</a>. This can be a helpful visualization of how words are broken apart and interpreted by large language models. Consider demonstrating this for the class and typing in example sentences. Most words will likely be interpreted as single words, but compound words like “decapod”, “anthology”, “pretense”, and “arachnophobia” are interpreted as two tokens instead of one.</details></p>|\n| ![](https://dancodedotorg.github.io/testing-slides/1FFfEhrNW-oNuq5dAk-yYxT6cxuPYxz19QdXr97T1PiI/slide10.png) | <p><i class=\"fa fa-file-text-o\" aria-hidden=\"true\"></i> <strong>Distribute:</strong> Pass out the Training Data Activity Guide<br><br></p>|\n| ![](https://dancodedotorg.github.io/testing-slides/1FFfEhrNW-oNuq5dAk-yYxT6cxuPYxz19QdXr97T1PiI/slide11.png) | <p><i class=\"fa fa-check-square-o\" aria-hidden=\"true\"></i> <strong>Do This:</strong> Read the overview of this document as a class. This text is also provided on the slide.<br></p>|\n| ![](https://dancodedotorg.github.io/testing-slides/1FFfEhrNW-oNuq5dAk-yYxT6cxuPYxz19QdXr97T1PiI/slide12.png) | <p><i class=\"fa fa-check-square-o\" aria-hidden=\"true\"></i> <strong>Do This:</strong> Have students complete each of the tables individually, listing examples of data sources in each location that could be used to help a large-language model represent different words. This requires identifying objects in these locations with text - literally any object - and imagining the words a language model could learn if it scanned the object.<br><br>Since the first example is “This Classroom”, you could do an example together as a class and point out any posters or books or anything with text. An easy example is the slide itself being projected, which would help a language model represent words like “Do”, “Complete”, Include”, etc.<br><br>It’s not vital that students finish every aspect of this guide, since they will work in a group in the next section of this lesson. With that in mind, consider setting a timer to ensure students finish with enough time to move to the next part of the activity.<br><br><i class=\"fa fa-refresh\" aria-hidden=\"true\"></i> <strong>Circulate:</strong> Monitor students as they complete this guide, noticing especially unique words or examples that can be useful to highlight in the next activity. If students are struggling, encourage them to visualize what it would look like if a computer sat in the middle of a space and scanned anything it saw - what words or symbols would it encounter?<br><br>The next part of this activity requires making a poster - during this time, also be thinking about how you will distribute supplies to groups so they are ready to start right away with the next task.<br></p>|\n| ![](https://dancodedotorg.github.io/testing-slides/1FFfEhrNW-oNuq5dAk-yYxT6cxuPYxz19QdXr97T1PiI/slide13.png) | <p><i class=\"fa fa-check-square-o\" aria-hidden=\"true\"></i> <strong>Do This:</strong> Read the text on the slide to the class. Have students form groups of 3-4 people with a poster paper and markers. Each person should write the words from their activity guide onto the posters. They do not have to write the source they got it from. Groups should also find a way to emphasize words that are common across group members, such as writing it large or with special emphasis.<br><br>Set a short timer for this activity. When a group is finished, their poster paper essentially represents a language model trained from a variety of sources curated by each student. These can be referred to in later parts of the unit as our understanding of language models evolves.<br><br><i class=\"fa fa-refresh\" aria-hidden=\"true\"></i> <strong>Circulate:</strong> Ensure all students are able to participate and add their words to the poster. Emphasize and celebrate situations where a unique word appears on a poster that other models in the classroom likely won’t have.<br><br><details style=\"background-color: #FFA400; padding: 10px; margin-bottom: 10px; border: 1px solid transparent; border-radius: 5px; color: white\"><summary style=\"font-size: 1.2em; font-weight: bold;\"><i class=\"fa fa-lightbulb-o \"></i> Teaching Tip: What Do Models “Know” At This Point?</summary><br>The language being used in this lesson is very intentional, saying that models can “represent” words as opposed to “know” or “understand”. Students may pick up on this and ask what the models really “know” or “understand” at this point, or you may hear students saying the model “knows what this word means” which isn’t quite correct. At this stage, all we’re doing is building a “word bank” that a model can recognize and eventually reproduce. But the model doesn’t have any inherent understanding of the meaning of these words - this happens in later steps and later lessons. If we asked a model to respond to a prompt just with the training done today, it could generate any of the words students are putting on their posters, but the results would be random and nonsensical since it doesn’t have any tools to help it make decisions about which words are best used in which situations. Nevertheless, this is a necessary step in understanding how a language model works - a model can’t even begin to “understand” a word if it’s not even included in it’s training data.</details></p>|\n| ![](https://dancodedotorg.github.io/testing-slides/1FFfEhrNW-oNuq5dAk-yYxT6cxuPYxz19QdXr97T1PiI/slide15.png) | <p><i class=\"fa fa-microphone\" aria-hidden=\"true\"></i> <strong>Say:</strong> These are some great models we’re building - such a wide variety of words they’re able to represent just from the sources we have close to us. But let’s imagine we want to make sure we’re providing enough data so it can eventually be used for certain tasks.<br><br><i class=\"fa fa-check-square-o\" aria-hidden=\"true\"></i> <strong>Do This:</strong> In the following slides, a certain type of task will be presented. Students will discuss in groups what additional data sources would be necessary to make sure our model can represent the words needed for this task.<br><br><details style=\"background-color: #8C52BA; padding: 10px; margin-bottom: 10px; border: 1px solid transparent; border-radius: 5px; color: white\"><summary style=\"font-size: 1.2em; font-weight: bold;\"><i class=\"fa fa-lightbulb-o \"></i> Assessment Opportunity: Formative Assessment</summary><br>The following prompts can be used as a formative assessment to see how members of the class understand the relationship between data sources used as input and the types of words a language model can represent from that source. You can get a pulse-check on this understanding by listening to how students respond as a class, or having them discuss in groups first and listen in on the conversations, or have students use the blank space on the back of their activity guide to write down their answers before responding. If you notice students are struggling to answer these questions, consider doing one or two as a class to model how students should think about this relationship between training data and what a model can represent.</details></p>|\n| ![](https://dancodedotorg.github.io/testing-slides/1FFfEhrNW-oNuq5dAk-yYxT6cxuPYxz19QdXr97T1PiI/slide16.png) | <p><i class=\"fa fa-comments\" aria-hidden=\"true\"></i> <strong>Discuss:</strong> What data sources should we use to make sure our model can… Give a recipe and steps for making chili</p><p><br><i class=\"fa fa-lightbulb-o\" aria-hidden=\"true\"></i> <strong>Discussion Goal:</strong> Possible answers can include:</p><ul><li>Recipe books</li><li>Instruction manuals for kitchen appliances</li><li>History of chili cookoffs</li></ul><p>Optional: If any student posters seem to have any words relevant to this task, consider highlighting that poster as already having some relevant training data to this task.<br></p>|\n| ![](https://dancodedotorg.github.io/testing-slides/1FFfEhrNW-oNuq5dAk-yYxT6cxuPYxz19QdXr97T1PiI/slide17.png) | <p><i class=\"fa fa-comments\" aria-hidden=\"true\"></i> <strong>Discuss:</strong> What data sources should we use to make sure our model can… Recommend places to hike in the southwest<br><br><i class=\"fa fa-lightbulb-o\" aria-hidden=\"true\"></i> <strong>Discussion Goal:</strong> Possible answers can include:</p><ul><li>Travel books</li><li>Maps of Arizona</li><li>Hike Reviews</li></ul><p>Optional: If any student posters seem to have any words relevant to this task, consider highlighting that poster as already having some relevant training data to this task.<br></p>|\n| ![](https://dancodedotorg.github.io/testing-slides/1FFfEhrNW-oNuq5dAk-yYxT6cxuPYxz19QdXr97T1PiI/slide18.png) | <p><i class=\"fa fa-comments\" aria-hidden=\"true\"></i> <strong>Discuss:</strong> What data sources should we use to make sure our model can… Help with math homework<br><br><i class=\"fa fa-lightbulb-o\" aria-hidden=\"true\"></i> <strong>Discussion Goal:</strong> Possible answers can include:</p><ul><li>Math textbooks</li><li>Multiplication tables</li><li>How to be a good tutor books</li></ul><p>Optional: If any student posters seem to have any words relevant to this task, consider highlighting that poster as already having some relevant training data to this task.<br></p>|\n| ![](https://dancodedotorg.github.io/testing-slides/1FFfEhrNW-oNuq5dAk-yYxT6cxuPYxz19QdXr97T1PiI/slide19.png) | <p><i class=\"fa fa-comments\" aria-hidden=\"true\"></i> <strong>Discuss:</strong> What data sources should we use to make sure our model can… Give relationship advice</p><p><br><i class=\"fa fa-lightbulb-o\" aria-hidden=\"true\"></i> <strong>Discussion Goal:</strong> Possible answers can include:</p><ul><li>Teen magazines (teen vogue / cosmo)</li><li>Self-help books</li><li>Fashion magazines</li></ul><p>Optional: If any student posters seem to have any words relevant to this task, consider highlighting that poster as already having some relevant training data to this task.</p>|\n| ![](https://dancodedotorg.github.io/testing-slides/1FFfEhrNW-oNuq5dAk-yYxT6cxuPYxz19QdXr97T1PiI/slide20.png) | <p><i class=\"fa fa-comments\" aria-hidden=\"true\"></i> <strong>Discuss:</strong> Even with all of this extra information and all of the data we’ve sourced so far, there are still limits to what our models can do… If we wanted our models to know the largest number of words possible, what do you think is a good data source to use?<br><br><i class=\"fa fa-lightbulb-o\" aria-hidden=\"true\"></i> <strong>Discussion Goal:</strong> This is intended to be a quick question with a single right answer: The internet. If students give answers other than this, continue to prompt them with “Yah, but what’s even bigger than that…” and work towards getting students to consider the internet as a large data source. If the conversation reaches a lull, just tell the class “The Internet”.<br><br><i class=\"fa fa-microphone\" aria-hidden=\"true\"></i> <strong>Say:</strong> The models we’ve started to make today are a great start and represent a good starting collection of words, but can’t possibly encompass all of the data we’d need to represent the entire world and all of its complexity. To solve this, most modern large language models are trained on huge collections of information usually from the internet, such as the entirety of wikipedia. By using such large quantities of data, large-language models are able to build up huge libraries of words they recognize and represent natural language.<br><br><details style=\"background-color: #FFA400; padding: 10px; margin-bottom: 10px; border: 1px solid transparent; border-radius: 5px; color: white\"><summary style=\"font-size: 1.2em; font-weight: bold;\"><i class=\"fa fa-lightbulb-o \"></i> Teaching Tip: Looking Inside the Box</summary><br>The article <a href=\"https://drive.google.com/file/d/1fl7G-4LOuuC0qhHVPbMuOragjhhUDqqC/view?usp=drive_link\">“Inside the secret list of websites that make AI like ChatGPT sound smart”</a> from the Washington Post has a detailed list of how the internet and various websites have been used to train current large-language models. We don’t recommend using this article for classroom use as aspects may not be appropriate, but the interactive web version of the article (link here) includes an interactive component where you can type in the name of a website and see if it’s been used to train large language models (if the website is behind a paywall, consider investigating if your local library allows limited free access). This can be a useful illustration of just how much data was used to train large-language models.</details></p>|\n| ![](https://dancodedotorg.github.io/testing-slides/1FFfEhrNW-oNuq5dAk-yYxT6cxuPYxz19QdXr97T1PiI/slide21.png) | <p><br></p>|\n| ![](https://dancodedotorg.github.io/testing-slides/1FFfEhrNW-oNuq5dAk-yYxT6cxuPYxz19QdXr97T1PiI/slide22.png) | <p>[Still todo: make the graphic organizer]<br></p>|\n| ![](https://dancodedotorg.github.io/testing-slides/1FFfEhrNW-oNuq5dAk-yYxT6cxuPYxz19QdXr97T1PiI/slide23.png) | <p><br></p>|\n\n"
      },
      "seeding_key": {
        "activity_section.key": "cc099d73-e862-4dba-a446-0daa0ea9e364",
        "lesson_activity.key": "5a041a6e-6665-460e-abd1-33cf8ebaa862"
      }
    }
  ],
  "script_levels": [

  ],
  "levels_script_levels": [

  ],
  "resources": [

  ],
  "lessons_resources": [

  ],
  "scripts_resources": [

  ],
  "scripts_student_resources": [

  ],
  "vocabularies": [

  ],
  "lessons_vocabularies": [

  ],
  "lessons_programming_expressions": [

  ],
  "objectives": [

  ],
  "lessons_standards": [

  ],
  "lessons_opportunity_standards": [

  ],
  "rubrics": [

  ],
  "learning_goals": [

  ],
  "learning_goal_evidence_levels": [

  ]
}
