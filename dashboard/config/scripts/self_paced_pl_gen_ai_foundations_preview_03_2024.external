name 'self-paced-pl-gen-ai-foundations-preview-03_2024'
title 'title'
description 'description here'

markdown <<MARKDOWN
# Embeddings

## Lesson Highlight: Character Quiz Activity

<img src="https://images.code.org/9a52d33d49d488c302d04354a96a3d2d-bed5925cbfe2b9a80368293aa21cf84b-Slide19.PNG" alt="character repersentations by Kim and Hawa  representations" width="350px" style="border: 2px solid black; border-radius: 8px; float:right; margin: 20px 20px 20px 20px">

#### During **Lesson 4: Understanding Embeddings**, students investigate how characters from stories or movies can be similar as a way to understand how words can be similar.

#### Students do the following...
* #### Create a representation of chosen characters based on their different traits.
* #### Collect data on other characters by sharing with classmates.
* #### Compare two characters row-by-row, noticing when dots are close together or far apart. For example, Kim and Hawa's characters are on opposite ends of the good/bad spectrum, but are close in several other areas. 

<img src="https://images.code.org/5587e0a3e25e4642f2da11c4f317800e-3d83c1f988e645b8de16c95ee6709055-Slide22.PNG" alt="character representations shown as a matrix of numbers" width="350px" style="border: 2px solid black; border-radius: 8px; float:right; margin: 20px 20px 20px 20px">

#### During discussions, students will eventually understand that they can compare numbers in each position to determine how similar or different characters are. One powerful insight is that it doesn‚Äôt matter what each position represents, only how close or far the numbers are in that same position.

#### These key concepts helps us generalize the idea of ‚Äúcharacter traits‚Äù to **embeddings** which are the set of numbers used to represent a word in a large-language model.

## Lesson Previews

<details style="background-color: #ececec; padding: 10px; margin-bottom: 10px; border: 1px solid transparent; border-radius: 5px;">
    <summary style="font-size: 1.5em; font-weight: bold;">üîé Lesson 4: Understanding Embeddings</summary>
<div style="margin-top: 20px; margin-left: 20px; margin-right: 20px;">
    <p>
<img src="https://images.code.org/f8f255ae13beed4bb8255ee46c235786-170a15084c6c3ae34f619c8d0ff22954-Slide27.PNG" alt="embeddings definition" width="300px" style="float:left; margin: 20px 20px 20px 20px;">

#### **Question of the Day:** How do computers represent the meanings of words?

#### **Lesson Overview:**

#### In this lesson, students explore how language models understand and represent word meanings. Beginning with a game, they investigate the concept of words being "close" in meaning. This leads to an activity where students assume the roles of fictional characters, using a sequence of numbers to represent their "character traits" and comparing these numerical representations to others. The lesson demonstrates that language models use a similar method, known as embeddings, to represent words as sequences of numbers, with similar words being numerically close to each other. The lesson concludes with students updating the storage section of their graphic organizer to encapsulate the idea of word embeddings.

#### **Students will be able to:**
* #### Describe how embeddings show the similarity or difference between two items
* #### Explain how language models use embeddings to store the meaning of wordss

### <a href="https://levelbuilder-studio.code.org/s/gen-ai-staging/lessons/4" target="blank" rel="noopener noreferrer">Full Lesson Plan</a>
</p></div>
</details>

<details style="background-color: #ececec; padding: 10px; margin-bottom: 10px; border: 1px solid transparent; border-radius: 5px;">
    <summary style="font-size: 1.5em; font-weight: bold;">üîé Lesson 5: Embeddings: How They're Created</summary>
<div style="margin-top: 20px; margin-left: 20px; margin-right: 20px;">
    <p>
<img src="https://images.code.org/088a71b0747a8b137cd39ac44767ce18-c25ee550d58ce9ea5e005f9a5bb11a4d-Slide19.PNG" alt="completed tabel from lesson activity" width="300px" style="float:left; margin: 20px 20px 20px 20px;">

#### **Question of the Day:** How do language models learn the embeddings they use to represent words?

#### **Lesson Overview:**

#### In this lesson, students delve into the creation of word embeddings. They start by interpreting a passage in a made-up language, using context clues to understand word meanings based on their relationships with other words. Following this, they engage in an activity to construct embeddings from sentences by noting word proximity. The climax reveals that students worked with two distinct passages, illustrating how the same word can have different representations based on its usage context. This insight sets the stage for upcoming lessons on how language models use sentence structure and context to determine word meanings accurately.

#### **Students will be able to:**
* #### Construct an embedding for a text passage
* #### Explain how different passages can create different embeddings

### <a href="https://levelbuilder-studio.code.org/s/gen-ai-staging/lessons/5" target="blank" rel="noopener noreferrer">Full Lesson Plan</a>
</p></div>
</details>


MARKDOWN
