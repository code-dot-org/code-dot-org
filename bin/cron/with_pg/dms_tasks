#!/usr/bin/env ruby

# This script runs the AWS Data Migration Service tasks that replicate data from
# our reporting RDS database to our Redshift database. It is highly tied to the
# AWS DMS tasks in the us-east-1 region.
# (https://console.aws.amazon.com/dms/home?region=us-east-1#tasks:)

require File.expand_path('../../../../deployment', __FILE__)
require 'cdo/chat_client'
require 'cdo/only_one'
require 'cdo/rake_utils'
require 'cdo/slack'

RakeUtils.with_bundle_dir(File.dirname(__FILE__)) do
  require 'cdo/redshift'
end

REPLICATION_TASK_TYPE = 'reload-target'.freeze
SECONDS_PER_MINUTE = 60

# A hash of AWS Redshift DB schemas to the groups allowed to access it.
SCHEMA_PERMISSIONS = {
  analysis: ['admin', 'reader', 'reader_pii'],
  dashboard_production: ['admin', 'reader', 'reader_pii'],
  dashboard_production_pii: ['admin', 'reader_pii'],
  pegasus: ['admin', 'reader', 'reader_pii'],
  pegasus_pii: ['admin', 'reader_pii']
}.freeze

# @param task_execution_time_sec [Integer] The number of seconds the task's
#   previous execution took.
# @return [Integer] The number of seconds to wait before launching the next DMS
#   task. This attempts to be a slight overestimate of the task's execution
#   time.
def get_delay(task_execution_time_sec)
  # Note that we add 300 seconds since the time AWS DMS reports does not include
  # the (non-negligible) amount of time spent "starting" the task.
  if task_execution_time_sec > 60 * SECONDS_PER_MINUTE
    return (task_execution_time_sec * 1.1 + 300).to_i
  end
  if task_execution_time_sec > 30 * SECONDS_PER_MINUTE
    return (task_execution_time_sec * 1.2 + 300).to_i
  end
  return (task_execution_time_sec * 1.3 + 300).to_i
end

# The main method, responsible for creating a DMS client, fetching the set of
# replication tasks, and starting the replication tasks.
def main
  # Update the data room topic in Slack.
  new_topic = 'Tableau data is automatically reloading (details in channel infra-dms)...'
  Slack.update_topic('data', new_topic)

  # Create a DMS client and use it to start task replication.
  dms_client = Aws::DatabaseMigrationService::Client.new
  dms_client.describe_replication_tasks.replication_tasks.each do |replication_task|
    task_name = replication_task.replication_task_identifier
    next unless task_name.start_with? 'cron'

    task_arn = replication_task.replication_task_arn
    # TODO(asher): Gracefully handle the case when the DMS task has never been run.
    task_execution_time = replication_task.replication_task_stats.elapsed_time_millis / 1000
    task_delay = get_delay(task_execution_time)

    ChatClient.message 'infra-dms',
      "Starting DMS task #{task_name} (sleep duration: #{task_delay})...",
      color: 'green'

    dms_client.start_replication_task(
      {
        replication_task_arn: task_arn,
        start_replication_task_type: REPLICATION_TASK_TYPE
      }
    )
    sleep(task_delay)

    ChatClient.message 'infra-dms', "Finished DMS task #{task_name}.", color: 'green'
  end

  SCHEMA_PERMISSIONS.each do |schema, groups|
    sql = "GRANT SELECT ON ALL TABLES IN SCHEMA #{schema} TO " +
      groups.map {|group| "GROUP #{group}"}.join(', ')
    RedshiftClient.instance.exec(sql)
    ChatClient.message 'infra-dms', "Reset permissions on schema #{schema}.", color: 'green'
  end

  # Update the "data" room summary in Slack.
  new_topic = "Tableau data is good (reloaded #{DateTime.now.strftime('%Y-%m-%d')})"
  Slack.update_topic('data', new_topic)
rescue Aws::DatabaseMigrationService::Errors::ServiceError => e
  # Log the exception to "infra-dms" and "data" rooms in Slack.
  ChatClient.message 'infra-dms',
    "EXCEPTION: #{e.message}",
    color: 'red'
  new_topic = 'Tableau data is bad. :('
  Slack.update_topic('data', new_topic)

  # Re-raise the exception for HoneyBadger visibility.
  raise e
end

main if only_one_running?(__FILE__)
