#!/usr/bin/env ruby

require 'csv'
require_relative '../../dashboard/config/environment'

def get_substring_in_between(text, begin_string, end_string)
  text.split(begin_string).last.split(end_string).first
end

def valid_json?(string)
  !!JSON.parse(string)
rescue JSON::ParserError
  false
end

def get_blocked_by_details(blocked_by, details)
  if details.class != Hash
    return details
  end
  case blocked_by
  when "openai"
    return {
      evaluation: details[:evaluation]
    }.to_json
  when "comprehend"
    return {
      flagged_text: details[:flagged_segment],
      toxicity: details[:toxicity],
      max_category: details[:max_category][:name],
      score: details[:max_category][:score]
    }.to_json
  when "blocklist"
    return {flagged_text: details[:blocked_word]}.to_json
  when "webpurify"
    return {flagged_text: details[:content]}.to_json
  else
    return {}.to_json
  end
end

def main
  options = {}
  OptionParser.new do |opts|
    opts.on('--section_id SECTION_ID') do |section_id|
      options[:section_id] = Integer(section_id)
    end
  end.parse!

  CSV.open("aichat_requests.csv", "w") do |csv|
    headers = %w[
      aichat_request_id user_id username name path created_at updated_at model_id role chat_message status blocked_by block_by_details
    ]
    csv << headers

    student_users_in_section = Section.find(options[:section_id]).followers.map(&:student_user)
    teacher_users_in_section = Section.find(options[:section_id]).active_section_instructors.map(&:instructor)
    all_users_in_section = student_users_in_section + teacher_users_in_section
    rows = AichatRequest.where(
      user: all_users_in_section,
    )

    rows.each do |row|
      user = row.user
      response = row.response
      user_message_text = JSON.parse(row.new_message)["chatMessageText"]
      execution_status = row.execution_status
      selected_model_id = JSON.parse(row.model_customizations)["selectedModelId"]
      path = row.level_id
      # In case a data row does not include level_id.
      if row.level_id.is_a? Integer
        level = Level.find(row.level_id)
        script_level = level.script_levels.find_by_script_id(row.script_id)
        if script_level
          # This handles chat requests that occurred on standard levels in a progression
          path = script_level.path
        else
          # This handles chat requests that occurred on a sublevel
          parent_levels = BubbleChoice.parent_levels(level.name)
          parent_levels_in_script = parent_levels.filter do |pl|
            pl.script_levels.any? {|sl| sl.script_id == row.script_id}
          end

          if parent_levels_in_script
            parent_level = parent_levels_in_script.first
            sublevel_position = parent_level.sublevel_position(level)
            path = parent_level.build_script_level_path(
              parent_level.script_levels.first,
              {sublevel_position: sublevel_position}
            )
          end
        end
      end

      if execution_status == SharedConstants::AI_REQUEST_EXECUTION_STATUS[:USER_PROFANITY]
        # Parse response for openai/comprehend/blocklist/webpurify details for user message.
        # There is no model response recorded if user message was flagged.
        # After https://github.com/code-dot-org/code-dot-org/pull/61095, response was updated to JSON.
        # Only handle json responses.
        if valid_json?(response)
          user_safety_layer_response = JSON.parse(response).deep_symbolize_keys
          user_blocked_by = user_safety_layer_response[:blocked_by]
          details = user_safety_layer_response[:details]
          user_blocked_by_details = get_blocked_by_details(user_blocked_by, details)
        end
      elsif execution_status == SharedConstants::AI_REQUEST_EXECUTION_STATUS[:MODEL_PROFANITY]
        # Model response is recorded in addition to blocked by service details.
        # After https://github.com/code-dot-org/code-dot-org/pull/61095, response was updated to JSON.
        # Only handle json responses.
        if valid_json?(response)
          model_safety_layer_response = JSON.parse(response).deep_symbolize_keys
          model_message_text = model_safety_layer_response[:text]
          model_blocked_by = model_safety_layer_response[:blocked_by]
          details = model_safety_layer_response[:details][:evaluation]
          model_blocked_by_details = get_blocked_by_details(model_blocked_by, details)
        end
      elsif execution_status == SharedConstants::AI_REQUEST_EXECUTION_STATUS[:SUCCESS]
        # Model response is recorded.
        model_message_text = response
      end
      # No model response recorded when unexpected error or user input too large.

      base_row = [
        row.id,
        row.user_id,
        user.username,
        user.name,
        path,
        row.created_at,
        row.updated_at,
        selected_model_id,
      ]

      status =
        case execution_status
        when SharedConstants::AI_REQUEST_EXECUTION_STATUS[:SUCCESS] || SharedConstants::AI_REQUEST_EXECUTION_STATUS[:MODEL_PROFANITY]
          "SUCCESS"
        when SharedConstants::AI_REQUEST_EXECUTION_STATUS[:FAILURE]
          "UNEXPECTED_ERROR #{response}"
        when SharedConstants::AI_REQUEST_EXECUTION_STATUS[:USER_PROFANITY]
          "USER_PROFANITY_DETECTED"
        when SharedConstants::AI_REQUEST_EXECUTION_STATUS[:USER_INPUT_TOO_LARGE]
          "USER_INPUT_TOO_LARGE"
        else
          "UNKNOWN"
        end

      # Add user message to csv.
      csv << [
        *base_row,
        'user',
        user_message_text,
        status,
        user_blocked_by,
        user_blocked_by_details
      ]

      next if execution_status != SharedConstants::AI_REQUEST_EXECUTION_STATUS[:SUCCESS] && execution_status != SharedConstants::AI_REQUEST_EXECUTION_STATUS[:MODEL_PROFANITY]
      if execution_status == SharedConstants::AI_REQUEST_EXECUTION_STATUS[:MODEL_PROFANITY]
        status = "model profanity detected"
      end
      # Add assistant message to csv.
      csv << [
        *base_row,
        'assistant',
        model_message_text,
        status,
        model_blocked_by,
        model_blocked_by_details
      ]
    end
  end
end

main
