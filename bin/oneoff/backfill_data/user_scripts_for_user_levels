#!/usr/bin/env ruby

# This script creates a UserScript for every row in the input CSV file.
#
# This script will be run with a CSV containing the user IDs, script IDs, and associated timestamps
# for the approximately ZZZK production UserScripts that remain to be backfilled by
# User#backfill_user_scripts. As there other instances of a UserLevel (with a script_id) existing
# without the corresponding UserScript existing, we "fix" them here as well.
#
# This CSV will be created via SQL run on AWS Redshift, as the reporting database is not performant
# enough.
#
#   SELECT DISTINCT
#     users.id AS user_id,
#     user_levels.script_id,
#     MIN(user_levels.created_at) AS started_at,
#     MAX(user_levels.updated_at) AS last_progress_at,
#     COUNT(0) AS num_levels
#   FROM users
#   INNER JOIN user_levels
#     ON user_levels.user_id = users.id
#   LEFT OUTER JOIN user_scripts
#     ON user_scripts.user_id = users.id
#       AND user_scripts.script_id = user_levels.script_id
#   WHERE user_scripts.id IS NULL
#   GROUP BY 1,2;
#
# The NUM_LEVELS_REQUIRED hash below was created from analysing this SQL.
#
#   SELECT
#     script_id,
#     num_levels,
#     COUNT(0) AS num_users
#   FROM (
#     SELECT DISTINCT
#       users.id AS user_id,
#       user_levels.script_id,
#       MIN(user_levels.created_at) AS started_at,
#       MAX(user_levels.updated_at) AS last_progress_at,
#       COUNT(0) AS num_levels
#     FROM users
#     INNER JOIN user_levels
#       ON user_levels.user_id = users.id
#     LEFT OUTER JOIN user_scripts
#       ON user_scripts.user_id = users.id
#         AND user_scripts.script_id = user_levels.script_id
#     WHERE user_levels.script_id IS NOT NULL AND user_scripts.id IS NULL
#     GROUP BY 1,2
#     ORDER BY 1,2
#   )
#   GROUP BY 1, 2
#   ORDER BY 1, 2;
#
# After this script is run, User#backfill_user_scripts will be removed.

require 'csv'
require_relative '../../../dashboard/config/environment'

# A hash mapping a script_id to the number of levels required for "completion". Commented IDs
# reflect a threshold sufficiently large that none of the corrupt data is anywhere near
# completion or a deleted script.
NUM_LEVELS_REQUIRED = {
  1 => 98,
  2 => 20,
  6 => 10,
  17 => 128,
  # 18 => 149,
  # 19 => 167,
  22 => 8,
  # 23 => 161,
  # 25 => 20,
  26 => 15,  # Based on historical distribution, not existing script_levels.
  # 30
  # 32 => 32,
  # 34 => 10,
  # 41 => 48,
  # 56 => 62,
  # 57
  # 63 => 85,
  # 66
  # 71
  # 72 => 27,
  # 73 => 10,
  # 91 => 3,
  # 96 => 6,
  # 100 => 3,
  # 102 => 11,
  # 105 => 15,
  106 => 11,
  # 107 => 15,
  # 108 => 14,
  # 114 => 73,
  # 116 => 83,
  # 117
  # 118
  # 122
  # 123
  # 124
  # 125
  # 126
  # 128
  # 132 => 4,
  # 137 => 25,
  142 => 10,  # This may be an under-estimate as the result of LevelGroup UserLevel's.
  143 => 5,  # This may be an under-estimate as the result of LevelGroup UserLevel's.
  144 => 5,  # This may be an under-estimate as the result of LevelGroup UserLevel's.
  # 151
  # 152
  # 156 => 11,
  # 158
  # 168
  # 169
  171 => 2,  # This may be an under-estimate as the result of LevelGroup UserLevel's.
  172 => 2,  # This may be an under-estimate as the result of LevelGroup UserLevel's.
  173 => 2,  # This may be an under-estimate as the result of LevelGroup UserLevel's.
  177 => 2,  # This may be an under-estimate as the result of LevelGroup UserLevel's.
  178 => 2,  # This may be an under-estimate as the result of LevelGroup UserLevel's.
  179 => 2  # This may be an under-estimate as the result of LevelGroup UserLevel's.
  # 181
  # 184 => 8,
  # 188
  # 190
  # 191
  # 192
  # 193
  # 194
  # 195
  # 196 => 12,  # This may be an under-estimate as the result of LevelGroup UserLevel's.
  # 197 => 12,  # This may be an under-estimate as the result of LevelGroup UserLevel's.
  # 198 => 12,
  # 199 => 8,
  # 203
  # 204
}.freeze
SCRIPTS = Script.all.pluck(:id).freeze
TRANSACTION_SIZE = 5_000
TIME_NOW = Time.now.freeze

# An array of (user_id, script_id, started_at, last_progress_at) triples.
data = []
# The CSV filename.
filename = ARGV[0]

# Process the CSV, reading the CSV line by line and writing the rows in
# transaction batches.
puts 'READING CSV...'
CSV.foreach(filename, headers: true) do |line|
  # Append the CSV row to our list of rows to create.
  user_id = line['user_id'].to_i
  script_id = line['script_id'].to_i
  started_at = line['started_at']
  last_progress_at = line['last_progress_at']
  num_levels = line['num_levels'].to_i

  # As the existence of a UserScript for deleted scripts causes errors on various pages of ours, we
  # skip creating a UserScript.
  next unless SCRIPTS.include? script_id

  completed_at = nil
  if (NUM_LEVELS_REQUIRED.key? script_id) && num_levels >= NUM_LEVELS_REQUIRED[script_id]
    completed_at = last_progress_at
  end

  data << [user_id, script_id, started_at, last_progress_at, completed_at]
end
puts "READ CSV (kept #{data.length} rows)."

user_id_script_id = nil
slice_count = 0
puts 'BEGINNING DB WRITES...'
begin
  data.each_slice(TRANSACTION_SIZE) do |data_slice|
    puts "  WRITING SLICE #{slice_count}."
    ActiveRecord::Base.transaction do
      data_slice.each do |user_id, script_id, started_at, last_progress_at, completed_at|
        user_id_script_id = "#{user_id} , #{script_id}"

        user_script = UserScript.find_by(
          user_id: user_id,
          script_id: script_id
        )
        next if user_script

        UserScript.create!(
          user_id: user_id,
          script_id: script_id,
          created_at: TIME_NOW,
          updated_at: TIME_NOW,
          started_at: started_at,
          last_progress_at: last_progress_at,
          completed_at: completed_at
        )
      end
    end

    slice_count += 1
  end
rescue Exception => e
  puts "EXCEPTION: #{user_id_script_id}..."
  raise e
end
puts 'FINISHED DB WRITES.'
