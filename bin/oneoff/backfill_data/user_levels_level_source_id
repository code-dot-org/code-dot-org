#!/usr/bin/env ruby

# This script populates the `level_source_id` column of the `user_levels` table,
# if not already present, using the data in a CSV file. The CSV file itself is
# constructed from a mysqldump of a temporary table created by the following
# MySQL.
#
#   CREATE TABLE backfill_#{LOW_ID}_#{HIGH_ID} AS
#   SELECT
#     t.user_levels_id,
#     activities.level_source_id
#   FROM (
#     SELECT
#       user_levels.id AS user_levels_id
#       MAX(activities.id) AS activities_id
#     FROM user_levels
#     INNER JOIN activities
#       ON activities.user_id = user_levels.user_id
#         AND activities.level_id = user_levels.level_id
#     WHERE user_levels.id >= #{LOW_ID}
#       AND user_levels.id < #{HIGH_ID}
#       AND user_levels.level_source_id IS NULL
#       AND activities.level_source_id IS NOT NULL
#     GROUP BY user_levels_id
#   ) AS t
#   INNER JOIN activities
#     ON activities.id = t.activities_id;
#
# The first command-line argument, filename, specifies the CSV file.
# The second command-line arugment, batch_size, specifies the number of
#   user_levels updated per transaction. The number of lines in the CSV file
#   controls the total number of user_levels updated (across all transactions).
#
# Note that, observationally, approximately 1% of activities do not have a
# level_source_id. Thus, after running this script, there will be UserLevel rows
# without a level_source_id.

require_relative '../../../dashboard/config/environment'

if ARGV.length != 2
  puts 'Usage: ./bin/oneoff/backfill_data/user_levels_level_source_id filename batch_size'
  exit 1
end

filename = ARGV[0]
batch_size = ARGV[1].to_i

# Since the updated_at field is used as a proxy for "last_progress_at" for the
# user_level, we intentionally do not want to modify that field.
ActiveRecord::Base.record_timestamps = false

begin
  # Read the contents of the file, saving them to a hash so that we can update
  # all UserLevel's associated with a fixed LevelSource at once.
  puts "Building update_hash..."
  update_hash = Hash.new {|hash, key| hash[key] = []}
  CSV.foreach(filename) do |line|
    user_levels_id = line[0].to_i
    level_source_id = line[1].to_i
    update_hash[level_source_id] << user_levels_id
  end

  puts "Built update_hash with #{update_hash.size} distinct level_source_id's."

  # Transform the hash into an array of hashes, each with batch_size many keys,
  # for batching in transactions.
  count = 0
  update_hash_batches = []
  current_hash = {}
  update_hash.each_pair do |level_source_id, user_levels_id_array|
    if count % batch_size == 0
      update_hash_batches << current_hash
      current_hash = {}
    end
    current_hash[level_source_id] = user_levels_id_array

    count += 1
  end

  puts "Built update_hash_batches with #{update_hash_batches.size} batches."

  # Perform the actual DB updates, batched in transactions.
  update_hash_batches.each_with_index do |batch, index|
    puts "Processing batch #{index}..."
    ActiveRecord::Base.transaction do
      batch.each do |level_source_id, user_levels_id_array|
        UserLevel.where(id: user_levels_id_array).
          update_all(level_source_id: level_source_id)
      end
    end
  end
ensure
  ActiveRecord::Base.record_timestamps = true
end
