#!/usr/bin/env ruby

require_relative '../../../dashboard/config/environment'
require 'cdo/aws/s3'
require 'optparse'
require 'json'
require 'uri'
require 'date'
require 'csv'
require 'cdo/redshift'
require 'aws-sdk-sts'
require 'cdo/json_to_redshift_table_validator'

# This script redelivers application event ('firehose') event records to Redshift from the Intermediate S3 bucket
# where batches of records were stored by the Firehose data stream and where manifest objects identify the batches
# that succeeded delivery to Redshift and those that failed delivery to Redshift.

CDO.log = Logger.new($stdout)

options = {}
options[:actually_redeliver] = false
options[:modify_invalid] = false
options[:log_filename] = 'batch_redelivery_log.csv'
OptionParser.new do |opts|
  opts.banner = "Usage: bin/oneoff/data_fix/redeliver_application_event_records_to_redshift [options]"
  opts.on("-a", "--actually-redeliver", "Actually redeliver messages") do
    options[:actually_redeliver] = true
  end
  opts.on("-m", "--modify-invalid", "Modify invalid messages") do
    options[:modify_invalid] = true
  end
  opts.on("-l", "--log-filename FILE", "Set the log filename") do |file|
    options[:log_filename] = file
  end
  opts.on("-h", "--help", "Displays this help message") do
    puts opts
    exit
  end
end.parse!
CDO.log.info "Called with options: #{options}"

class SkipRedeliveryError < StandardError; end

# TODO: Limit the range of batches to reprocess. Until then, pick a single prefix and reprocess all matching error manifests.
ERROR_MANIFESTS_PREFIX = 'errors/manifests/2024/07/14'.freeze
# START_DATE_TIME = ???
# END_DATE_TIME = ???

FIREHOSE_STREAM = 'analysis-events'.freeze
FIREHOSE_INTERMEDIATE_BUCKET = 'firehose-analysis-events'.freeze
REDELIVER_DATA_PREFIX = 'redeliveries'.freeze
REDELIVERY_MANIFESTS_PREFIX = REDELIVER_DATA_PREFIX + '/manifests'
REDELIVERY_ERROR_MANIFESTS_PREFIX = REDELIVER_DATA_PREFIX + '/errors'
REDSHIFT_SCHEMA = 'analysis'.freeze
REDSHIFT_TABLE = 'application_events'.freeze
sts_client = Aws::STS::Client.new
ACCOUNT_ID = sts_client.get_caller_identity.account

event_json_schema = {
  type: "redshift_table",
  columns: {
    created_at: {
      type: "timestamp without time zone",
      nullable: false
    },
    environment: {
      type: "character",
      maxLength: 128,
      nullable: false
    },
    study: {
      type: "character",
      maxLength: 128,
      nullable: false
    },
    study_group: {
      type: "character",
      maxLength: 128
    },
    device: {
      type: "character",
      maxLength: 1024
    },
    uuid: {
      type: "character",
      maxLength: 128
    },
    user_id: {
      type: "integer"
    },
    script_id: {
      type: "integer"
    },
    level_id: {
      type: "integer"
    },
    project_id: {
      type: "character",
      maxLength: 128
    },
    event: {
      type: "character",
      maxLength: 128,
      nullable: false
    },
    data_int: {
      type: "integer"
    },
    data_float: {
      type: "double precision"
    },
    data_string: {
      type: "character",
      maxLength: 4096
    },
    data_json: {
      type: "character varying",
      maxLength: 65535
    }
  }
}

s3_client = AWS::S3.create_client
redshift_client = RedshiftClient.instance

continuation_token = nil

BatchRedeliveryStatus = Struct.new(
  :error_manifest_object_key,               # S3 Key of Manifest Object that identifies undelivered (error) batches.
  :undelivered_batch_object_key,            # S3 Key of undelivered (error) batch Object specified in Error Manifest
  :undelivered_batch_position_in_manifest,  # A single error manifest can reference more than one undelivered batch.
  :records_in_batch,                        # Number of records in original batch.
  :records_modified,                        # Number of invalid records that were modified for redelivery.
  :records_skipped,                         # Number of invalid records that were skipped for redelivery (not fixable, or modify option disabled).
  :redelivery_batch_object_key,             # S3 Key of modified batch.
  :redelivery_manifest_object_key,          # S3 Key of redelivery manifest.
  :redelivery_date_time,                    # Date/Time redelivery to Redshift was completed (if successful).
  :redelivery_status,                       # true / false
  :redelivery_status_reason                 # Detailed error if status is false.
)

batches_processed = 0
batches_redelivered = 0
batches_failed = 0

# Log each batch that we attempt to redeliver.
CSV.open(options[:log_filename], 'a') do |batch_log_csv|
  batch_log_csv << BatchRedeliveryStatus.members if File.empty?(options[:log_filename])
  # List all Firehose error manifests matching a date prefix in batches until there are no more to list.
  loop do
    list_error_manifests_response = s3_client.list_objects_v2(
      bucket: FIREHOSE_INTERMEDIATE_BUCKET,
      prefix: ERROR_MANIFESTS_PREFIX,
      continuation_token: continuation_token
    )

    CDO.log.info "Retrieving #{list_error_manifests_response.contents.length} error manifests."
    # Iterate through each Firehose error manifest within the current batch.
    list_error_manifests_response.contents.each do |error_manifest_object|
      CDO.log.info "Error Manifest: #{error_manifest_object.key}"
      error_manifest_json = s3_client.get_object(
        bucket: FIREHOSE_INTERMEDIATE_BUCKET,
        key: error_manifest_object.key
      ).body.read
      # Iterate through each undelivered/errored Firehose batch identified in the current error manifest.
      JSON.parse(error_manifest_json)["entries"].each_with_index do |entry, position_in_error_manifest|
        batches_processed += 1
        undelivered_batch_uri = URI.parse(entry["url"])
        batch_status = BatchRedeliveryStatus.new
        batch_status.error_manifest_object_key = error_manifest_object.key
        batch_status.undelivered_batch_object_key = undelivered_batch_uri.path&.delete_prefix('/')
        batch_status.undelivered_batch_position_in_manifest = position_in_error_manifest
        batch_status.records_modified = 0
        batch_status.records_skipped = 0
        CDO.log.info "Attempting to redeliver error batch: #{batch_status.undelivered_batch_object_key}"
        undelivered_batch = s3_client.get_object(
          bucket: undelivered_batch_uri.host,
          key: batch_status.undelivered_batch_object_key
        ).body.read
        modified_batch = ''
        # Split JSON batch text into an array of JSON record strings and iterate over the event records, validating each one.
        undelivered_batch.
          delete_prefix('{').
          delete_suffix('}').
          split('}{').
          map {|obj| "{#{obj}}"}.
          tap {|array| batch_status.records_in_batch = array.length}.
          each_with_index do |record_string, _position_in_batch|
          modified_record_string, record_validation_status = Cdo::JSONtoRedshiftTableValidator.validate(record_string, event_json_schema, modify_invalid: options[:modify_invalid])
          batch_status.records_modified += 1 if record_validation_status && options[:modify_invalid]
          modified_batch += modified_record_string
        rescue Cdo::JSONtoRedshiftTableValidator::ValidationError => exception
          batch_status.records_skipped += 1
          CDO.log.info record_string
          CDO.log.info exception.message
        end
        raise SkipRedeliveryError.new('Skipping redelivery. --actually-redeliver is set to false.') unless options[:actually_redeliver]
        batch_status.redelivery_batch_object_key = REDELIVER_DATA_PREFIX + undelivered_batch_uri.path
        begin
          redelivery_manifest = {
            entries: [
              {
                url: "s3://#{FIREHOSE_INTERMEDIATE_BUCKET}/#{batch_status.redelivery_batch_object_key}",
                mandatory: true,
                meta: {
                  content_length: modified_batch.encode('UTF-8').bytesize
                }
              }
            ]
          }
          # Check if there's a manifest for successful redelivery of this batch because Redshift does not enforce
          # unique constraints and we must avoid duplicate redelivery.
          s3_client.head_object(bucket: FIREHOSE_INTERMEDIATE_BUCKET, key: REDELIVERY_MANIFESTS_PREFIX + undelivered_batch_uri.path)
          CDO.log.info "The batch #{undelivered_batch_uri.path} has already been redelivered."
          batches_failed += 1
        rescue Aws::S3::Errors::NotFound
          # Redelivery manifest does not exist, load the batch identified in the manifest into Redshift and then upload the manifest.
          s3_client.put_object(bucket: FIREHOSE_INTERMEDIATE_BUCKET, key: batch_status.redelivery_batch_object_key, body: modified_batch)
          load_batch_query = <<~SQL
            SET search_path TO #{REDSHIFT_SCHEMA};
            COPY #{REDSHIFT_TABLE} (created_at, environment, study, study_group, device, uuid, user_id, script_id, level_id, project_id, event, data_int, data_float, data_string, data_json)
            FROM 's3://#{FIREHOSE_INTERMEDIATE_BUCKET}/#{batch_status.redelivery_batch_object_key}'
            CREDENTIALS 'aws_iam_role=arn:aws:iam::#{ACCOUNT_ID}:role/redshift-s3'
            json 'auto' timeformat 'auto';
          SQL
          redshift_client.exec(load_batch_query)
          s3_client.put_object(
            bucket: FIREHOSE_INTERMEDIATE_BUCKET,
            key: REDELIVERY_MANIFESTS_PREFIX + undelivered_batch_uri.path,
            body: redelivery_manifest.to_json
          )
          batch_status.redelivery_manifest_object_key = REDELIVERY_MANIFESTS_PREFIX + undelivered_batch_uri.path
          batch_status.redelivery_date_time = DateTime.now.to_s
          batch_status.redelivery_status = true
          batches_redelivered += 1
          CDO.log.info "Successfully redelivered #{undelivered_batch_uri.path} to Redshift."
        end
      rescue RedshiftClient::PostgreSQLQueryError, Aws::Errors::ServiceError, SkipRedeliveryError, StandardError => exception
        batches_failed += 1
        CDO.log.info "Error redelivering batch: #{undelivered_batch_uri.path}"
        CDO.log.info exception.message
        s3_client.put_object(
          bucket: FIREHOSE_INTERMEDIATE_BUCKET,
          key: REDELIVERY_ERROR_MANIFESTS_PREFIX + undelivered_batch_uri.path,
          body: redelivery_manifest
        )
        batch_status.redelivery_manifest_object_key = REDELIVERY_ERROR_MANIFESTS_PREFIX + undelivered_batch_uri.path
        batch_status.redelivery_status = false
        batch_status.redelivery_status_reason = exception.message
      ensure
        batch_log_csv << batch_status
        batch_log_csv.flush
      end
    end
    break unless list_error_manifests_response.is_truncated
    continuation_token = list_error_manifests_response.next_continuation_token
  end
end

CDO.log.info "Script completed."
CDO.log.info "Batches Processed: #{batches_processed}"
CDO.log.info "Batches Successfully Redelivered: #{batches_redelivered}"
CDO.log.info "Batches Failed Redelivery: #{batches_failed}"
